from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Synthetic dataset
texts = [
    "Breaking: President signs new healthcare reform bill.",  # Real
    "Scientists confirm cure for cancer hidden by Big Pharma.",  # Fake
    "Local election results show increase in voter turnout.",  # Real
    "Aliens spotted in the White House.",  # Fake
    "Government launches clean energy incentives.",  # Real
    "Celebrities confess to being lizard people.",  # Fake
]
labels = ['REAL', 'FAKE', 'REAL', 'FAKE', 'REAL', 'FAKE']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)

# Vectorize text using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_vec, y_train)

# Evaluate the model
y_pred = model.predict(X_test_vec)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Function to classify new news text
def detect_fake_news(text):
    vec = vectorizer.transform([text])
    prediction = model.predict(vec)
    return prediction[0]

# Test the function
sample = "New policy offers free healthcare to all citizens."
print("Prediction for sample:", detect_fake_news(sample))
